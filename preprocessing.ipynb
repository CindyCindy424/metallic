{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.hub\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from torchvision.datasets import *\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# from torchsummary import summary\n",
    "# import tensorboardX as tbx\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from PIL import *\n",
    "import cv2\n",
    "from cv2 import *\n",
    "\n",
    "from utility.output import *\n",
    "from utility.metrics import computeMetrics\n",
    "from utility.network_process import net_freeze_layer\n",
    "from utility.plot import plotResultCurve\n",
    "# from utility.edataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 模型保存文件路径\n",
    "MODEL_SAVE_PATH = './model'\n",
    "#### 数据路径\n",
    "DATA_PATH = r'E:\\buffer\\dataset\\train'\n",
    "\n",
    "# 定义Summary_Writer\n",
    "# tensorboard --logdir=D:\\IDE\\MyProject\\python\\jupyter_notebook\\Research\\git-metallic\\metallic\\log_res\n",
    "# writer = SummaryWriter(log_dir='./log_res',comment='resnet18')   # 数据存放在这个文件夹\n",
    "# writer.export_scalars_to_json(\"./log_res/all_scalars.json\")\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentTime():\n",
    "    return datetime.datetime.strftime(datetime.datetime.fromtimestamp(time.time()),format='%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "#### 模型保存\n",
    "def checkpoint(model, optimizer, epoch, useTimeDir=False):\n",
    "    # 保存整个模型  \n",
    "    state = {'net':model.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':epoch}\n",
    "    model_name = str(model).split('(')[0]\n",
    "    if useTimeDir is True:\n",
    "        savePath = './'+MODEL_SAVE_PATH+'/'+getCurrentTime()\n",
    "        os.mkdir(savePath)\n",
    "    else:\n",
    "        savePath = MODEL_SAVE_PATH\n",
    "    dir = os.path.join(savePath,model_name+'_model.pth')\n",
    "    torch.save(state, dir)\n",
    "    return savePath if useTimeDir else None\n",
    "\n",
    "#### 模型恢复\n",
    "def modelrestore(model):\n",
    "    model_name = str(model).split('(')[0]\n",
    "    dir = os.path.join(MODEL_SAVE_PATH,model_name+'_model.pth')\n",
    "    checkpoint = torch.load(dir)\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    epoch = checkpoint['epoch'] + 1\n",
    "    return model, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 4\n",
    "BATCH_SIZE = 6\n",
    "NUM_CLASS = 4\n",
    "CV = 1\n",
    "\n",
    "SCHEDULE_EPOCH = 5\n",
    "SCHEDULE_REGRESS = 0.2\n",
    "\n",
    "### 部分训练\n",
    "_PARTIAL_TRAIN = True\n",
    "_PARTIAL_TRAIN_RATIO = 0.003\n",
    "\n",
    "### 冻结网络\n",
    "_NET_FREEZE = True\n",
    "_NET_NO_GRAD = []\n",
    "\n",
    "P_lr = 1e-3\n",
    "train_ratio = 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### image transformation for original images\n",
    "data_transform_origin = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "#### image transformation for augmented images\n",
    "data_transform_aug = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# full_dataset = ImageFolder(DATA_PATH,transform = data_transform)\n",
    "\n",
    "\n",
    "class EDataset(Data.Dataset):\n",
    "\n",
    "    def __init__(self, root_path, basic_transform, aug_transform, aug_ratio=0.3):\n",
    "        self.root_path = root_path\n",
    "        self.basic_transform = basic_transform\n",
    "        self.aug_transform = aug_transform\n",
    "        self.image_origin = ImageFolder(self.root_path,\n",
    "                                        transform = self.basic_transform)\n",
    "        self.image_augment = ImageFolder(self.root_path,\n",
    "                                        transform = self.aug_transform)\n",
    "        self.len_origin = len(self.image_origin)\n",
    "        self.len_augment = int(len(self.image_augment)*aug_ratio)\n",
    "        self.idx_augment = np.random.permutation(len(self.image_augment))\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_origin + self.len_augment\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx<self.len_origin:\n",
    "            item = self.image_origin[idx]\n",
    "        else:\n",
    "            item = self.image_augment[ self.idx_augment[idx-self.len_origin] ]\n",
    "        return item\n",
    "\n",
    "    \n",
    "def getModel(NUM_CLASS,name='se_resnet50'):\n",
    "    return torch.hub.load(\n",
    "            'moskomule/senet.pytorch',\n",
    "            name,\n",
    "            num_classes=NUM_CLASS\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "full_dataset = EDataset(DATA_PATH,basic_transform=data_transform_origin,aug_transform=data_transform_aug)\n",
    "total_size = len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_metrics = []\n",
    "epoch_save = 0\n",
    "\n",
    "for cv in range(CV):\n",
    "    \n",
    "    hub_model = getModel(NUM_CLASS=NUM_CLASS,name='se_resnet50')\n",
    "    \n",
    "    #### load model\n",
    "    print('DEBUG:: fold ',cv)\n",
    "    try:\n",
    "        hub_model, epo = modelrestore(hub_model)\n",
    "        print('Model successfully loaded')\n",
    "        print('-' * 60)\n",
    "    except Exception as e:\n",
    "        print('Model not found, use the initial model')\n",
    "        epo = 0\n",
    "        print('-' * 60)\n",
    "        \n",
    "    net = hub_model\n",
    "    \n",
    "    #### define criterian & optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=P_lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, SCHEDULE_EPOCH, SCHEDULE_REGRESS)\n",
    "    \n",
    "    #### use CUDA if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "    \n",
    "    \n",
    "    #### data splitting\n",
    "    if _PARTIAL_TRAIN:\n",
    "        full_dataset, _ = torch.utils.data.random_split(full_dataset, \n",
    "                                                        [\n",
    "                                                            int(_PARTIAL_TRAIN_RATIO*total_size),\n",
    "                                                            total_size - int(_PARTIAL_TRAIN_RATIO*total_size) \n",
    "                                                        ])\n",
    "        total_size = int(_PARTIAL_TRAIN_RATIO*total_size)\n",
    "        \n",
    "    train_size = int(np.floor( total_size * train_ratio ))\n",
    "    test_size = int(total_size - train_size)\n",
    "    dataset_train, dataset_test = torch.utils.data.random_split(full_dataset, [train_size,test_size])\n",
    "    \n",
    "    #### training\n",
    "    _loss = []\n",
    "    __record_train_num = 0\n",
    "    epoch_save = epo\n",
    "    for epoch in range(epo, EPOCH):  # loop over the dataset multiple times\n",
    "        epoch_save += 1\n",
    "        print('DEBUG:: training epoch ',epoch)\n",
    "        trainloader = Data.DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        testloader = Data.DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            #### get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #### zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #### forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #### print statistics\n",
    "            running_loss += loss.item()\n",
    "            _loss.append(running_loss)\n",
    "            \n",
    "            __record_train_num += len(labels)\n",
    "            if __record_train_num % (BATCH_SIZE * 50) == 0:\n",
    "                print('DEBUG:: num has trained',__record_train_num)\n",
    "            if i % 50 == 0:\n",
    "                print('DEBUG:: trainloader:{}/{}'.format(i, len(trainloader)))\n",
    "            if i % 50 == 0:\n",
    "                try:\n",
    "                    checkpoint(net, optimizer, epoch_save)\n",
    "                    print('*' * 60)\n",
    "                    print('Model is saved successfully at epoch {}'.format(str(epoch)))\n",
    "                    print('*' * 60)\n",
    "                except Exception as e:\n",
    "                    print('*' * 60)\n",
    "                    print('Something is wrong!',e)\n",
    "                    print('*' * 60)\n",
    "                    \n",
    "        #### predicting\n",
    "        print('=' * 60)\n",
    "        print('i:', i)\n",
    "        print('Start predicting')\n",
    "        Ypred = []\n",
    "        Ytest = []\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs, -1)\n",
    "                Ytest.extend(labels.tolist())\n",
    "                Ypred.extend(predicted.tolist())\n",
    "\n",
    "        _metrics.append(computeMetrics(Ypred,Ytest))\n",
    "        print(\"accuracy is {}\".format(_metrics[-1]['acc']) )\n",
    "        print(\"auc is {}\".format(_metrics[-1]['auc']) )\n",
    "        print('=' * 60)\n",
    "    \n",
    "\n",
    "print('-' * 60)\n",
    "print('Training is over, saving the model')\n",
    "print('-' * 60)\n",
    "try:\n",
    "    savePath = checkpoint(net, optimizer, epoch_save, useTimeDir=True)\n",
    "    saveResult(_metrics,savePath)\n",
    "    print('Model is saved successfully')\n",
    "except Exception as e:\n",
    "    print('Something is wrong!',e)\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### plotting\n",
    "plotResultCurve(_metrics,['acc','auc'],'acc-auc')\n",
    "plotResultCurve(_metrics,['fpr','tpr'],'fpr-tpr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
