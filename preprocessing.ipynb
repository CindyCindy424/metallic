{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cv2 import *\n",
    "from scipy.ndimage import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.hub\n",
    "import os\n",
    "from torchvision.datasets import *\n",
    "import random\n",
    "import torch.utils.data as Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = r'D:\\onedrive\\eyisheng\\OneDrive\\files\\大三下\\科研\\金属分类\\data'\n",
    "DATA_ROOT_CORROSION = DATA_ROOT + r'\\corrosion'\n",
    "DATA_ROOT_NONCORROSION = DATA_ROOT + r'\\noncorrosion'\n",
    "\n",
    "DATASET_ROOT = './dataset'\n",
    "DATASET_ROOT_TRAIN = os.path.join(DATASET_ROOT,'train')\n",
    "DATASET_ROOT_TEST = os.path.join(DATASET_ROOT,'test')\n",
    "DATASET_TRAIN_POS = os.path.join(DATASET_ROOT_TRAIN,'1')\n",
    "DATASET_TRAIN_NEG = os.path.join(DATASET_ROOT_TRAIN,'0')\n",
    "DATASET_TEST_POS = os.path.join(DATASET_ROOT_TEST,'1')\n",
    "DATASET_TEST_NEG = os.path.join(DATASET_ROOT_TEST,'0')\n",
    "\n",
    "if not os.path.exists(DATASET_ROOT_TRAIN):\n",
    "    os.mkdir(DATASET_ROOT_TRAIN)\n",
    "\n",
    "if not os.path.exists(DATASET_ROOT_TEST):\n",
    "    os.mkdir(DATASET_ROOT_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#### get raw jpg files from directories\n",
    "def getFileNames(is_corrosion=False):\n",
    "    path_files = []\n",
    "    walk_root = DATA_ROOT_NONCORROSION if is_corrosion==False else DATA_ROOT_CORROSION\n",
    "    \n",
    "    for root, dirs, files in os.walk(walk_root):\n",
    "        for f in files:\n",
    "            fpath = os.path.join(root,f)\n",
    "            path_files.append(fpath)\n",
    "            \n",
    "    label = 0 if is_corrosion==False else 1\n",
    "    res = list(map(lambda x:(x,label),path_files))\n",
    "    return res\n",
    "\n",
    "\n",
    "def checkImgShape():\n",
    "    shapes = set()\n",
    "    for line in non_corrosion_files:\n",
    "        jpgfile = Image.open(line[0])\n",
    "        jpgfile = np.array(jpgfile)\n",
    "        shapes.add(jpgfile.shape)\n",
    "    return shapes\n",
    "\n",
    "\n",
    "def resizeImg(src,dsize):\n",
    "    jpgfile = Image.open(src)\n",
    "    jpgfile = np.array(jpgfile)\n",
    "    jpgfile = cv2.resize(jpgfile,dsize)\n",
    "    return jpgfile\n",
    "\n",
    "\n",
    "def preprocessingPipeline(src,target):\n",
    "    img = resizeImg(src,(256,256)) ### image shapes\n",
    "    return [src,target,img]\n",
    "    \n",
    "    \n",
    "def filesToImg(path_files):\n",
    "    train = []\n",
    "    test = []\n",
    "    for line in path_files:\n",
    "        if random.random()<0: ### train test split\n",
    "            test.append( preprocessingPipeline(line[0],line[1]) )\n",
    "        else:\n",
    "            train.append( preprocessingPipeline(line[0],line[1]) )\n",
    "    return {'train':train,'test':test}\n",
    "    \n",
    "    \n",
    "def saveImgToFiles(imgs):\n",
    "    \n",
    "    if not os.path.exists(DATASET_TRAIN_POS):\n",
    "        os.mkdir(DATASET_TRAIN_POS)\n",
    "    if not os.path.exists(DATASET_TRAIN_NEG):\n",
    "        os.mkdir(DATASET_TRAIN_NEG) \n",
    "    if not os.path.exists(DATASET_TEST_POS):\n",
    "        os.mkdir(DATASET_TEST_POS)\n",
    "    if not os.path.exists(DATASET_TEST_NEG):\n",
    "        os.mkdir(DATASET_TEST_NEG)\n",
    "        \n",
    "    for line in imgs['train']:\n",
    "        src = os.path.split(line[0])[-1]\n",
    "        if line[1]==0:\n",
    "            src = os.path.join(DATASET_TRAIN_NEG,src)\n",
    "        elif line[1]==1:\n",
    "            src = os.path.join(DATASET_TRAIN_POS,src)\n",
    "        Image.fromarray(line[2]).save(src)\n",
    "        \n",
    "    for line in imgs['test']:\n",
    "        src = os.path.split(line[0])[-1]\n",
    "        if line[1]==0:\n",
    "            src = os.path.join(DATASET_TEST_NEG,src)\n",
    "        elif line[1]==1:\n",
    "            src = os.path.join(DATASET_TEST_POS,src)\n",
    "        Image.fromarray(line[2]).save(src)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgWriter():\n",
    "    img_data = filesToImg(img_files)\n",
    "\n",
    "    saveImgToFiles(img_data)\n",
    "    return\n",
    "\n",
    "\n",
    "# non_corrosion_files = getFileNames(is_corrosion=False)\n",
    "# corrosion_files = getFileNames(is_corrosion=True)\n",
    "# img_files = corrosion_files\n",
    "# img_files.extend(non_corrosion_files)\n",
    "# del corrosion_files,non_corrosion_files\n",
    "# ImgWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\steve/.cache\\torch\\hub\\moskomule_senet.pytorch_master\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCH = 20\n",
    "BATCH_SIZE = 6\n",
    "NUM_CLASS = 2\n",
    "CV = 5\n",
    "\n",
    "P_momentem = 0.8\n",
    "P_lr = 1e-3\n",
    "train_ratio = 0.8 \n",
    "\n",
    "hub_model = torch.hub.load(\n",
    "    'moskomule/senet.pytorch',\n",
    "    'se_resnet20',\n",
    "    num_classes=NUM_CLASS,\n",
    "#     pre_trained=True\n",
    ")\n",
    "net = hub_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=P_lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "full_dataset = ImageFolder(DATASET_ROOT_TRAIN,transform = data_transform)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(np.floor( total_size * train_ratio ))\n",
    "test_size = int(total_size - train_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 2.272\n",
      "[1,    10] loss: 3.295\n",
      "[1,    15] loss: 3.944\n",
      "[2,     5] loss: 3.256\n",
      "[2,    10] loss: 2.807\n",
      "[2,    15] loss: 2.568\n",
      "[3,     5] loss: 2.202\n",
      "[3,    10] loss: 2.027\n",
      "[3,    15] loss: 1.918\n",
      "[4,     5] loss: 1.746\n",
      "[4,    10] loss: 1.686\n",
      "[4,    15] loss: 1.657\n",
      "[5,     5] loss: 1.586\n"
     ]
    }
   ],
   "source": [
    "_total_loss = []\n",
    "_total_acc = []\n",
    "\n",
    "for cv in range(CV):\n",
    "    \n",
    "    dataset_train, dataset_test = torch.utils.data.random_split(full_dataset, [train_size,test_size])\n",
    "    trainloader = Data.DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    testloader = Data.DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    _loss = []\n",
    "    for epoch in range(EPOCH):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            _loss.append(running_loss)\n",
    "            if i % 5 == 4:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, np.sum(_loss)/len(_loss)))\n",
    "    print('Finished Training')\n",
    "\n",
    "    \n",
    "    class_correct = list(0. for i in range(NUM_CLASS))\n",
    "    class_total = list(0. for i in range(NUM_CLASS))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            if type(c)!=list:\n",
    "                c = [c]\n",
    "            for i in range(np.min([BATCH_SIZE,len(labels)])):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    _acc = []\n",
    "    for i in range(NUM_CLASS):\n",
    "        print('Accuracy of  %f ' % ( 100 * class_correct[i] / class_total[i] ))\n",
    "        _acc.append(100 * class_correct[i] / class_total[i])\n",
    "    \n",
    "    \n",
    "    _total_loss.extend(_loss)\n",
    "    _total_acc.extend(_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(_total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
